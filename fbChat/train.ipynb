{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os, glob, json\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all chat data in JSON format\n",
    "chatData = {}\n",
    "for fin in glob.glob('inputs/message_*.json'):\n",
    "    with open(fin) as f:\n",
    "        data = f.read()\n",
    "        # for the first json file, chatData is empty -- update the dictionary\n",
    "        if 'messages' not in chatData:\n",
    "            chatData.update(json.loads(data))\n",
    "        # after the first, 'messages' exists and we don't want to overwrite it -- so extend the dictionary\n",
    "        else:\n",
    "            chatData['messages'].extend(json.loads(data)['messages'])\n",
    "\n",
    "# one key in the JSON is 'participants', which is a list of dictionaries with key 'name'\n",
    "persons = [p['name'] for p in chatData['participants']]\n",
    "\n",
    "# durp\n",
    "persons = ['C']\n",
    "\n",
    "# the other key in the JSON is 'messages', which is a list of dictionaries like: \n",
    "\"\"\"    \n",
    "{\"sender_name\": \"D\",\n",
    " \"timestamp_ms\": 1578769599245,\n",
    " \"content\": \"10s of thousands of messages\",\n",
    " \"type\": \"Generic\"\n",
    "},\"\"\"\n",
    "\n",
    "# create a DataFrame of all messages\n",
    "df = pd.DataFrame(chatData['messages'], columns = ['sender_name', 'timestamp_ms', 'content'])\n",
    "\n",
    "# giphy or photo messages have no 'content' are dropped\n",
    "df = df[df.content.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sender_name, flatten all messages into a single string\n",
    "# adding periods to separate sentences\n",
    "chatDataMerged = {}\n",
    "\n",
    "for p in persons:\n",
    "    messages = df[df.sender_name == p]['content'].tolist()\n",
    "    # remove leading periods for one weird person...\n",
    "    if p == 'C':\n",
    "        for i in range(len(messages)):\n",
    "            if messages[i].startswith('.'):\n",
    "                messages[i] = messages[i][1:]\n",
    "    chatDataMerged[p] = \". \".join(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequentializing person: C\n",
      "0 / 4622111\n",
      "1000000 / 4622111\n",
      "2000000 / 4622111\n",
      "3000000 / 4622111\n",
      "4000000 / 4622111\n"
     ]
    }
   ],
   "source": [
    "# create sub-sequences of 30 characters, and an array of the 31st characters for each\n",
    "# dict key is the sender_name in question\n",
    "X = { p : [] for p in persons }\n",
    "Y = { p : [] for p in persons }\n",
    "length = { p : len(chatDataMerged[p]) for p in persons }\n",
    "sequenceLength = 100\n",
    "\n",
    "import string\n",
    "charactersUsed = { p : sorted(list(set([c.lower() for c in chatDataMerged[p]]))) for p in persons }\n",
    "usefulCharacters = [c for c in string.ascii_lowercase] + [str(i) for i in range(10)]\n",
    "usefulCharacters.append(' ')\n",
    "usefulCharacters.append('.')\n",
    "\n",
    "for c in charactersUsed['C']:\n",
    "    if c not in usefulCharacters:\n",
    "        chatDataMerged['C'].replace(c, '')\n",
    "        \n",
    "charactersUsed = { p : sorted(list(set([c.lower() for c in chatDataMerged[p]]))) for p in persons }\n",
    "\n",
    "char_to_n = {}\n",
    "n_to_char = {}\n",
    "for p in persons:\n",
    "    char_to_n[p] = { c : n for n, c in enumerate(charactersUsed[p]) }\n",
    "    n_to_char[p] = { n : c for n, c in enumerate(charactersUsed[p]) }\n",
    "    \n",
    "for p in persons:\n",
    "    print('Sequentializing person:', p)\n",
    "    for i in range(length[p] - sequenceLength):\n",
    "        if (i % 1000000) == 0:\n",
    "            print(i, '/', length[p] - sequenceLength)\n",
    "        sequence = chatDataMerged[p][i:i + sequenceLength].lower()\n",
    "        label = chatDataMerged[p][i + sequenceLength].lower()\n",
    "        X[p].append([char_to_n[p][c] for c in sequence])\n",
    "        Y[p].append(char_to_n[p][label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape x into (number of sequences, length of each sequence, number of features)\n",
    "X_modified = { p : np.reshape(X[p], (len(X[p]), sequenceLength, 1)) for p in persons }\n",
    "X_modified = { p : X_modified[p] / float(len(charactersUsed[p])) for p in persons }\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# one-hot encoding\n",
    "Y_modified = { p : np_utils.to_categorical(Y[p]) for p in persons }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "# start with speaker C\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(400, input_shape = (X_modified['C'].shape[1], X_modified['C'].shape[2]), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(400))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified['C'].shape[1], activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 2577s 52ms/step - loss: 3.0931\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 2684s 54ms/step - loss: 3.0441\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_modified['C'][:50000], Y_modified['C'][:50000], epochs = 2, batch_size = 100)\n",
    "model.save_weights('fbChat_generator_400_0.2_400_0.2_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('fbChat_generator_400_0.2_400_0.2_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', ' ', 'a', ' ', 'm', 'i', 'n', 'd', '-', 'b', 'e', 'n', 'd', 'i', 'n', 'g', ' ', 'l', 'o', 'o', 'k', ' ', 'i', 'n', 't', 'o', ' ', 't', 'h', 'e', ' ', 'l', 'i', 'f', 'e', ' ', 'o', 'f', ' ', 'a', ' ', 'f', 'a', 'n', 'f', 'i', 'c', 't', 'i', 'o', 'n', ' ', 'w', 'r', 'i', 't', 'e', 'r', ' ', 'w', 'h', 'o', \"'\", 's', ' ', 'l', 'o', 's', 't', ' ', 'c', 'o', 'n', 't', 'r', 'o', 'l', ' ', 'o', 'v', 'e', 'r', ' ', 'h', 'e', 'r', ' ', 'o', 'w', 'n', ' ', 's', 't', 'o', 'r', 'y', '.', ' ', 'i', 'n']\n"
     ]
    }
   ],
   "source": [
    "# generating text\n",
    "import copy\n",
    "\n",
    "string_mapped = copy.deepcopy(X['C'][60000])\n",
    "full_string = [n_to_char['C'][v] for v in string_mapped]\n",
    "\n",
    "print(full_string)\n",
    "\n",
    "for i in range(100):\n",
    "    x = np.reshape(string_mapped, (1, len(string_mapped), 1))\n",
    "    x = x / float(len(charactersUsed['C']))\n",
    "    \n",
    "    predictionIndex = np.argmax(model.predict(x, verbose = 0))\n",
    "    sequence = [n_to_char[p][v] for v in string_mapped]\n",
    "    full_string.append(n_to_char['C'][predictionIndex])\n",
    "    #print('Adding:', n_to_char['C'][predictionIndex])\n",
    "    \n",
    "    string_mapped.append(predictionIndex)\n",
    "    string_mapped = string_mapped[1:len(string_mapped)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self but i bruised the shit out of my right foot. man i hate my stupid body. i didn't say, but i gue\n",
      "x   x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.55143128e-06, 2.29226047e-04, 1.50185466e-01, 1.29109336e-04,\n",
       "        1.25027983e-03, 8.50470751e-05, 2.50038662e-04, 3.03085399e-04,\n",
       "        1.36591079e-05, 7.70163909e-03, 1.20958364e-04, 7.79197580e-05,\n",
       "        1.46194885e-04, 2.35267900e-04, 3.90278967e-03, 2.60061561e-03,\n",
       "        4.48897332e-02, 2.56545632e-03, 1.10258430e-03, 1.20711362e-03,\n",
       "        1.28513738e-03, 1.11890980e-03, 9.50324873e-04, 6.65786094e-04,\n",
       "        4.44469915e-04, 4.21179197e-04, 6.05219684e-04, 3.57712066e-04,\n",
       "        6.44362997e-04, 8.15665408e-06, 1.12818299e-04, 4.41548211e-04,\n",
       "        1.33832917e-04, 1.24033936e-03, 7.68402970e-05, 2.09873433e-05,\n",
       "        4.37566487e-05, 1.02140948e-05, 7.60168496e-06, 2.71399360e-04,\n",
       "        1.14015980e-04, 6.85729682e-02, 1.32461404e-02, 1.41154211e-02,\n",
       "        2.93883309e-02, 6.32671639e-02, 2.05780659e-02, 2.54697446e-02,\n",
       "        3.90995964e-02, 5.80010116e-02, 2.52287323e-03, 1.36502553e-02,\n",
       "        3.34852338e-02, 1.48164835e-02, 4.87074740e-02, 6.11354187e-02,\n",
       "        1.72403362e-02, 6.13277196e-04, 4.17286605e-02, 6.50230348e-02,\n",
       "        6.39068633e-02, 3.25940289e-02, 7.75442738e-03, 1.99342035e-02,\n",
       "        1.12322217e-03, 1.55428387e-02, 1.03918777e-03, 6.96471670e-06,\n",
       "        1.35864593e-05, 7.19402169e-06, 6.21292056e-05, 7.35076173e-05,\n",
       "        1.51812819e-05, 8.63618607e-06, 1.09154444e-05, 3.25408837e-05,\n",
       "        1.47688634e-05, 9.93932645e-06, 1.65281072e-05, 9.19258400e-06,\n",
       "        1.10504652e-05, 5.86295573e-06, 1.77873499e-05, 2.10089329e-05,\n",
       "        4.52542190e-05, 1.37631932e-05, 7.30134161e-06, 1.42212521e-05,\n",
       "        7.51198377e-06, 1.88651084e-05, 1.13156593e-05, 5.54637882e-06,\n",
       "        9.85992756e-06, 9.26005487e-06, 1.29410300e-05, 1.06204216e-05,\n",
       "        1.22934332e-04, 1.04731607e-05, 8.18575973e-06, 1.09434823e-05,\n",
       "        9.56513213e-06, 4.83587110e-06, 6.47911074e-05, 1.27464864e-05,\n",
       "        2.26106185e-05, 1.18335502e-05, 7.60516559e-06, 8.51957429e-06,\n",
       "        1.20116501e-05, 5.73552552e-06, 5.98990346e-06, 4.93735797e-06,\n",
       "        1.77101338e-05, 1.44952282e-05, 8.03396597e-06, 8.11303107e-06,\n",
       "        1.30485487e-05, 6.56911789e-06, 1.13527021e-05, 1.22626307e-05,\n",
       "        1.08378563e-05, 1.23320942e-05, 8.83689063e-06, 8.53850179e-06,\n",
       "        4.78166066e-06, 1.43178731e-05, 1.52894117e-05, 4.50639709e-06,\n",
       "        1.42660792e-05, 1.12252019e-05, 1.13718008e-04, 6.69165865e-06,\n",
       "        9.98294854e-06, 1.05160871e-05, 7.88948455e-06, 1.01514688e-05,\n",
       "        1.31606081e-04, 7.31295813e-06, 3.73361581e-06, 1.18241978e-05,\n",
       "        9.88200372e-06, 6.16111811e-06, 1.01557871e-05, 1.43500374e-05,\n",
       "        9.40288373e-06, 1.17764375e-05, 5.41261179e-05, 6.17336354e-06,\n",
       "        6.80405446e-06]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining text\n",
    "durp = copy.deepcopy(X['C'][99])\n",
    "print(''.join([n_to_char['C'][v] for v in durp]))\n",
    "print('x', n_to_char['C'][2], 'x')\n",
    "x = np.reshape(durp, (1, len(durp), 1))\n",
    "x = x / float(len(charactersUsed['C']))\n",
    "model.predict(x, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ough. you always cura the doppleganger on the train. finally got this quest item. pabs man. oops esc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.1704848e-06, 1.0936117e-04, 3.1518346e-01, 3.7187550e-05,\n",
       "        7.5462344e-04, 4.3270116e-05, 1.0435227e-04, 1.3079423e-04,\n",
       "        4.7624349e-06, 6.0209949e-03, 4.4727742e-05, 3.5621655e-05,\n",
       "        5.5203949e-05, 8.6952597e-05, 2.5311841e-03, 1.5731669e-03,\n",
       "        4.1504517e-02, 1.3756292e-03, 5.1625690e-04, 5.5548886e-04,\n",
       "        6.2583247e-04, 5.1890360e-04, 4.3203504e-04, 2.7520704e-04,\n",
       "        2.1389550e-04, 1.7058531e-04, 2.2771077e-04, 1.3297841e-04,\n",
       "        3.0671334e-04, 1.9424137e-06, 3.5764657e-05, 1.6748840e-04,\n",
       "        5.4674354e-05, 7.0865126e-04, 3.1409538e-05, 5.2861296e-06,\n",
       "        1.6305392e-05, 2.6254854e-06, 2.2278764e-06, 1.0422894e-04,\n",
       "        3.1351989e-05, 3.7876554e-02, 7.0090797e-03, 7.1879383e-03,\n",
       "        2.2473382e-02, 1.1899500e-01, 1.0737858e-02, 2.3925828e-02,\n",
       "        3.6278326e-02, 4.0750910e-02, 1.1998548e-03, 8.2185753e-03,\n",
       "        2.7146451e-02, 8.4814196e-03, 4.0432453e-02, 4.6715308e-02,\n",
       "        1.2502933e-02, 3.2077017e-04, 3.7558828e-02, 4.8914827e-02,\n",
       "        3.5763569e-02, 2.4289127e-02, 4.9243211e-03, 8.7602222e-03,\n",
       "        5.0549390e-04, 1.3354797e-02, 4.9466692e-04, 1.4312725e-06,\n",
       "        4.1518183e-06, 1.9272609e-06, 1.7716002e-05, 2.9080647e-05,\n",
       "        4.5423544e-06, 2.1201165e-06, 3.0763963e-06, 7.5327407e-06,\n",
       "        3.9806700e-06, 2.7887440e-06, 3.8961384e-06, 2.3025655e-06,\n",
       "        2.7420288e-06, 1.3958748e-06, 5.0257031e-06, 5.6646541e-06,\n",
       "        1.8160737e-05, 3.8483645e-06, 1.3395274e-06, 3.6784018e-06,\n",
       "        2.1604480e-06, 4.1507810e-06, 3.0465199e-06, 1.2646967e-06,\n",
       "        2.7250890e-06, 2.4261956e-06, 4.4015846e-06, 2.7717854e-06,\n",
       "        5.4801207e-05, 3.0175090e-06, 1.9073017e-06, 2.9691180e-06,\n",
       "        2.4366648e-06, 1.1299753e-06, 2.1639837e-05, 3.3045480e-06,\n",
       "        6.6631201e-06, 2.7294011e-06, 2.4106942e-06, 2.1857627e-06,\n",
       "        2.7112410e-06, 1.2377161e-06, 1.3072264e-06, 1.2150308e-06,\n",
       "        4.7464478e-06, 3.7062055e-06, 2.2701345e-06, 2.4227666e-06,\n",
       "        3.0834749e-06, 1.7976387e-06, 3.0770184e-06, 3.2907230e-06,\n",
       "        2.5275911e-06, 3.0016370e-06, 2.6332161e-06, 2.2480194e-06,\n",
       "        1.1194338e-06, 3.7841471e-06, 3.7367449e-06, 1.1141841e-06,\n",
       "        3.6472293e-06, 2.2721206e-06, 3.9897557e-05, 1.7146582e-06,\n",
       "        2.7353788e-06, 1.7275033e-06, 2.1928511e-06, 2.7195097e-06,\n",
       "        4.2093263e-05, 2.1467943e-06, 1.0643488e-06, 3.0521410e-06,\n",
       "        2.3760444e-06, 1.5769349e-06, 2.7991625e-06, 3.2651831e-06,\n",
       "        2.3562682e-06, 3.6621782e-06, 1.5917551e-05, 1.5076937e-06,\n",
       "        1.6526498e-06]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['C'][60000]\n",
    "print(''.join([n_to_char['C'][v] for v in X['C'][9000]]))\n",
    "\n",
    "model.predict(np.reshape(X['C'][1], (1, 100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '#': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, '*': 12, '+': 13, ',': 14, '-': 15, '.': 16, '/': 17, '0': 18, '1': 19, '2': 20, '3': 21, '4': 22, '5': 23, '6': 24, '7': 25, '8': 26, '9': 27, ':': 28, ';': 29, '<': 30, '=': 31, '>': 32, '?': 33, '@': 34, '[': 35, '\\\\': 36, ']': 37, '^': 38, '_': 39, '`': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'x': 64, 'y': 65, 'z': 66, '{': 67, '|': 68, '}': 69, '~': 70, '\\x80': 71, '\\x81': 72, '\\x82': 73, '\\x83': 74, '\\x84': 75, '\\x85': 76, '\\x86': 77, '\\x87': 78, '\\x88': 79, '\\x89': 80, '\\x8a': 81, '\\x8b': 82, '\\x8c': 83, '\\x8d': 84, '\\x8e': 85, '\\x8f': 86, '\\x90': 87, '\\x91': 88, '\\x92': 89, '\\x93': 90, '\\x94': 91, '\\x95': 92, '\\x96': 93, '\\x97': 94, '\\x98': 95, '\\x99': 96, '\\x9a': 97, '\\x9b': 98, '\\x9c': 99, '\\x9d': 100, '\\x9e': 101, '\\x9f': 102, '\\xa0': 103, '¡': 104, '¢': 105, '£': 106, '¤': 107, '¥': 108, '¦': 109, '§': 110, '¨': 111, '©': 112, 'ª': 113, '«': 114, '¬': 115, '\\xad': 116, '®': 117, '¯': 118, '°': 119, '±': 120, '²': 121, '³': 122, '´': 123, 'µ': 124, '¶': 125, '·': 126, '¸': 127, '¹': 128, 'º': 129, '»': 130, '¼': 131, '½': 132, '¾': 133, '¿': 134, 'à': 135, 'â': 136, 'ã': 137, 'ä': 138, 'å': 139, 'æ': 140, 'ê': 141, 'ë': 142, 'ì': 143, 'í': 144, 'ï': 145, 'ð': 146, 'ñ': 147, 'ó': 148}\n"
     ]
    }
   ],
   "source": [
    "print(char_to_n['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
